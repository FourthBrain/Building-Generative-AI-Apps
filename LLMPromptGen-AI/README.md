# ğŸ’® LLMPromptGen-AI ğŸ’® (FourthBrain Sample Project)
## Predict LLM prompts, powered by MIXTRAL!
LLMPromptGen-AI is a fine-tuned LLM prompt predictor that can help you determine which prompts can give you your desired responses for your LLM

## ğŸ“” Notebooks
| Notebook | Purpose | Link                                                                                           |
| :-------- | :-------- | :------------------------------------------------------------------------------------------------ |
|  ğŸŒ¼**MIXTRAL-LoRA Fine-tuning Notebook**  | Fine-tune and run inference on the fine-tuned result | [Here](https://colab.research.google.com/github/bensethbell/Building-Generative-AI-Apps/blob/main/%F0%9F%92%AE%20LLMPromptGen-AI%20%F0%9F%92%AE%20Fine-Tuning%20MIXTRAL.ipynb) |
|  ğŸ–¥ï¸ **Synthetic Dataset Creation Notebook**  | Create Synthetic Data using OpenAI's API | [Here](https://colab.research.google.com/github/bensethbell/Building-Generative-AI-Apps/blob/main/Synthetic%20GPT-4%20Dataset%20Creation%20LLM%20Prompts.ipynb)   |

## ğŸ“š Data
Data are from the Mosaic Instruct 3 dataset. An instruction-following dataset with a large number of longform samples. However, we can also generate data synthetically with GPT-4. 

Data found [here](https://huggingface.co/datasets/mosaicml/instruct-v3)

## ğŸ’° Value Generation
With LLMPromptGenAI - deepen your understanding of techniques for prompt engineering to cue a specific model to give optimal results. 


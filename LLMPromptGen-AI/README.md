# 💮 LLMPromptGen-AI 💮 (FourthBrain Sample Project)
## Building a Generative AI Application with Mixtral - LLMPromptGen AI
LLMPromptGen-AI is a fine-tuned LLM prompt predictor that can help you determine which prompts can give you your desired responses for your LLM. 

Before you begin, you’ll want to make sure you have access to a few tools:

1. Hugging Face 🤗 
    1. Please make an account
    2. Ensure you have a read/write API access key created
2. Collab
    1. Your specific experiment might require a Premium Colab experience, you can find instructions on how to do that [here!](https://colab.research.google.com/notebooks/pro.ipynb)
3. Open AI
    1. If you will be fine-tuning any of [OpenAI’s models](https://platform.openai.com/docs/guides/fine-tuning), you will need an account, with an API access token
    2. If you will be leveraging any of OpenAI’s models for synthetic data creation, you will need an account with an API access token.

## 📔 Notebooks
| Notebook | Purpose | Link                                                                                           |
| :-------- | :-------- | :------------------------------------------------------------------------------------------------ |
|  🌼**MIXTRAL-LoRA Fine-tuning Notebook**  | Fine-tune and run inference on the fine-tuned result | [Here](https://colab.research.google.com/drive/17SPgWEkv2EIA3FgdTmLTIEb6avlOQSF2?usp=sharing) |
|  🖥️ **Synthetic Dataset Creation Notebook**  | Create Synthetic Data using OpenAI's API | [Here](https://colab.research.google.com/drive/1nTKZNVoDoWQ32sXI9NtnxFf0gCJgMqWR?usp=sharing)   |

## 📚 Data
Data are from the Mosaic Instruct 3 dataset. An instruction-following dataset with a large number of longform samples. However, we can also generate data synthetically with GPT-4. 

Data found [here](https://huggingface.co/datasets/mosaicml/instruct-v3)

## 💰 Value Generation
With LLMPromptGenAI - deepen your understanding of techniques for prompt engineering to cue a specific model to give optimal results. 

